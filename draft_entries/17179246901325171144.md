---
Title: '【論文解説, 実装】 Any-Resolution AI-Generated Image Detection by Spectral Learning. ~SPAI: 周波数パターンを用いたAI画像検知手法~'
EditURL: https://blog.hatena.ne.jp/okojoai/okojoai.hatenablog.com/atom/entry/17179246901325171144
Draft: true
---

こんにちは．Okojo AIに業務委託として携わっている倉沢です．
近年，画像生成モデルの急速な高度化により，生成画像は肉眼での判別がますます困難になっています．一方で，フェイク画像の拡散や真正性の担保といった観点から，AI生成画像検出 (AI-generated Image Detection; AID) の重要性は急速に高まっています．

本記事では，CVPR 2025採択の「Any-Resolution AI-Generated Image Detection by Spectral Learning」を取り上げ，AIDタスクが直面する課題を整理したうえで，周波数領域の学習に基づく手法 SPAI (SPectral AI-generated Image detection) のパイプラインを概説します．加えて実装パートでは，公開されている公式リポジトリおよび学習済み重みを用いて，SPAIを実際に動作させることを目的とします．

##### 要約
**論文解説**

- 本物の画像っぽさを基準にして，そこから外れたものをAI生成画像と判別する手法．
- リサイズを前提にしないAny-Resolution検出を可能にする工夫も導入．
- 実験では，様々なベンチマークに対して一貫して高い性能を記録し，実運用で想定される画像劣化に対する頑健性も計測．

**実装**

- あ
- あ

#####  紹介論文
- **タイトル**：Any-Resolution AI-Generated Image Detection by Spectral Learning
- **著者**：Dimitrios Karageorgiou, Symeon Papadopoulos, Ioannis Kompatsiaris, Efstratios Gavves
- **採択会議**：CVPR2025
- **発行日**：2024年11月28日
- **URL**：<[https://arxiv.org/pdf/2411.19417]>
- **公式リポジトリ**：<https://github.com/mever-team/spai>

### 論文解説
<u>**<span style="font-size: 150%">AI画像検出(AI-generated Image Detection; AID)タスクの背景と3つのアプローチ</span>**</u>

AIDタスクの3つのアプローチが存在します．本記事で紹介するSPAIは，3つ目の方法をとります．

1. 画像内に写るオブジェクトの意味的整合性に着目し，顔や身体・影・遠近法などに生じる不整合を検知することで判別する方法
2. 画像生成モデルが残す低レベルなアーティファクト（ノイズパターンやフィルタリング痕など）を手がかりとして判別する方法
3. 実画像の分布を学習し，その分布から外れる画像をAI生成画像として判別する方法

それぞれ有効な発想ですが，実運用を想定するとAIDが難しい理由もはっきりしています．

まず，1つ目の「意味的整合性（顔・影・遠近法など）」に頼る方法は直感的で分かりやすい一方，生成モデルが高品質化するほど目に見える破綻が減っていくのが根本的な手法の限界として挙げられます．
2つ目の「低レベルアーティファクト（ノイズやフィルタ痕）」ベースの手法は，モデルが変わると手がかりも変わるのが厄介です．手間やお金の問題から，画像生成モデル毎に検出モデルを作る訳にはいきません．

そこで，「実画像の分布」を判断に使用する3つ目が，近年の新しい道として出てきます．
AI生成画像の癖を捉えるのではなく，実画像の癖を捉えて，それを起点にその癖から外れる画像をAI生成画像として扱う発想ですね．
ただ，初期の試みは主に画素空間（テクスチャなど）の関係性を学習する方向に寄っていました．


<u>**<span style="font-size: 150%">SPAIの貢献1：スペクトル領域への拡張</span>**</u>

ここでSPAIが効いてくるのが，「実画像と生成画像は，周波数領域のほうが分けやすい」という先行研究による観察結果です．
論文では，この先行知見を踏まえた上で，「実画像のスペクトル分布」を不変で有効な基準にできると主張します．

SPAIの狙いを一言でいうと，

* 実画像だけで（ラベル不要に），「実画像らしいスペクトル分布」を学習．
* そこからのズレを，復元の上手さを目安に測り，生成画像を検出する．

という流れです．


<u>**<span style="font-size: 150%">SPAIの貢献2：Any-Resolutionへの対応</span>**</u>

AIDは，「犬か猫か」などの画像内の広い領域に占めるオブジェクトを当てる分類タスクではなく，画像内の微妙な違い（ノイズの偏りや高周波の出方など）を拾う分類タスクです．
つまり，検出に効く手がかりは，画像の細部に寄っていることが多いです．

ところが実運用では，SNS画像・スマホ写真・切り抜いた画像など入力画像のサイズはバラバラです．
これを一般的な画像認識のように，固定サイズに合わせるためリサイズやクロップをしてしまうと，AIDにとって重要な成分，とくに高周波側の情報を自分で落としてしまう可能性があります．
「周波数領域で分けたい」という発想を採るなら，なおさら，周波数の情報を潰す前処理は避けたいわけです．

そこでSPAIでは，画像を無理に固定解像度へ押し込むのではなく，任意解像度（Any-Resolution）のまま扱える設計を入れています．


<u>**<span style="font-size: 150%">スペクトル領域とは？</span>**</u>

SPAIの詳しい説明に入る前に，スペクトル領域（周波数領域）つまりは画像のフーリエ変換について簡単にまとめたいと思います．

ざっくり言うと，画像をさまざまな向き・さまざまな細かさのサイン波の重ね合わせとして表現し直す操作だと思ってください．
私たちが普段見ている画像は，ピクセルが並んだ空間領域の表現です．
一方でフーリエ変換をかけると，画像は空間周波数領域として表せるようになります．

以下の解説がわかりやすいと思います．

[https://www.clg.niigata-u.ac.jp/~medimg/practice_medical_imaging/imgproc_scion/5fourier/index.htm:embed:cite]

[https://www.youtube.com/watch?v=pCVdNYvORVw:embed:cite]


周波数が低い・高いといった表現がありますが，直感的にはこう捉えると楽です．

* 低周波情報（上）：画像のなだらかな変化（大きな塊、ぼんやりした陰影）
* 高周波情報（下）：画像の細かい変化（エッジ、細かい模様、粒状のテクスチャ）

[f:id:kurara_S:20260128164832p:plain:h300]
[f:id:kurara_S:20260128164902p:plain:h300]

解説ページでも，ぼけた画像は高周波が小さく，細かい模様やエッジが多い鮮鋭な画像ほど高周波が大きい，という対応で説明されています．



YouTube内のアインシュタインの絵を用いて行っていることを体験できるサイトがあるので，ぜひ遊んでみてください．

[https://monman53.github.io/2dfft/:embed:cite]



<u>**<span style="font-size: 150%">SPectral AI-generated Image detection(SPAI)</span>**</u>

それでは，ようやくSPAIの説明に入っていきます．

[f:id:kurara_S:20251126152909p:plain:h300]

大まかなパイプラインを簡単に一行で説明します．

1. ***Masked Spectral Learning***：実画像だけを使い，「低周波/高周波を欠損させた入力」から元画像の周波数構造を復元する自己教師あり学習で，実画像のスペクトル分布モデルを作る．
2. ***Spectral Reconstruction Similarity***：学習済みモデルを用いて「原画像・低周波画像・高周波画像」の特徴の整合性を比較し，その類似度を整合性スコア（SRS）として取り出す．
3. ***Spectral Context Vector***：画像がどの帯域にどれだけ情報を持つか等の周波数的文脈を要約し，2のスコアを状況込みで解釈できるよう文脈ベクトル（SCV）を添える．
4. ***Spectral Context Attention***：任意解像度をリサイズせず扱うため，パッチ単位で2・3を計算し，重要なパッチをattentionで重み付けして全体判定に集約（SCA）する．


[f:id:kurara_S:20251126152623p:plain]

それでは，それぞれ詳しく説明します．

<u><span style="font-size: 120%">1. Masked Spectral Learning</span></u>

まず，実画像のみを使用して，実画像のスペクトル分布のモデルを作ります．
SPAIでは，このフェーズを Masked Spectral Learning と呼び，フーリエ変換とマスク操作を組み合わせた自己教師あり学習として定式化しています．

具体的には，入力画像に対して2D離散フーリエ変換 (DFT) を施し，円形のマスクを用いて，

・中心側だけを通すマスク：低周波成分のみを残す

・周辺側だけを通すマスク：高周波成分のみを残す

という2種類のマスクを適用し，周波数領域で「低周波」「高周波」を分離します．

これらをそれぞれ逆フーリエ変換することで，

・低周波のみを含むぼやけた画像
・高周波のみを含むエッジ強調的な画像

という2つの劣化画像が得られます。

Masked Spectral Learning では，これらの劣化画像を入力として，元の実画像を再構成するニューラルネットワークを学習します．


学習のやり方はシンプルで，「低周波だけ見せる」または「高周波だけ見せる」という欠損入力を作り，そこから元の実画像を復元する穴埋め問題として学習します．重要なのは，ここで復元させたいのは「見た目がそれっぽい画像」ではなく，実画像に典型的な周波数構造そのものです．つまり，モデルは「欠けた帯域を、実画像らしい統計で補う」ことを要求されるため，結果として「実画像の周波数分布のモデル」ができあがる，という設計になっています．


<u><span style="font-size: 120%">2. Spectral Reconstruction Similarity</span></u>

Masked Spectral Learning により，スペクトルモデルGは「実画像の周波数分布」を再構成できるようになります．ここで重要なのは，実画像に対して学習した再構成モデルは，実画像の周波数 (欠損させた低周波/高周波) をより整合的に復元できる一方，AI生成画像では復元に歪みが出やすいという点です．SPAIでは，この整合/不整合を，周波数再構成そのものの画素誤差ではなく，潜在特徴空間の類似度統計として取り出します．

直観的には，実画像は「原画像・低周波・高周波」の特徴同士が整合しやすいのに対し，生成画像は周波数の繋がり方が不自然で，これらの整合が崩れるため，平均・分散の分布が変化しやすいことを利用した設計となっています．



<u><span style="font-size: 120%">3. Spectral Context Vector</span></u>

SRSには，同じSRS値でも「画像がそもそもどれだけ高周波を含むか」などの文脈によって解釈が変わることに対処できません．例えば，もともと高周波成分が乏しい画像では，「高周波再構成に関するSRS」は判別に寄与しにククなります．そこでSRSを「どんなスペクトル文脈で計算したか」を表す補助情報として Spectral Context Vector (SCV) を導入します．

SCVは，画像の周波数的な性質（どの帯域が強いか/どれくらい多様か）を文脈として要約し,SRSと一緒に使えるようにします．言い換えると，SRSを「状況込みで解釈するためのメタ情報」がSCVです．これにより，SRSが同じ値でも「その値がどれくらい怪しいのか」を画像ごとに判断しやすくなります．

<u><span style="font-size: 120%">4. Spectral Context Attention</span></u>

ここまでのSRS/SCVは，ViTのトークン列を前提とするため，入力解像度が上がるほど計算が重くなります．そこでSPAIは，任意解像度をリサイズせず扱うためにSCAを導入します．
SCAはこのジレンマに対して，画像を無理に縮めるのではなく，画像をパッチに分割して，それぞれのパッチでSRS/SCVを計算し，最後に重要なパッチを重点的に集約するという設計を取ります．

<u>**<span style="font-size: 150%">性能</span>**</u>

学習には
検証は，13種類の生成手法と5種類の実画像ソースからなるテストセットで比較しています．

下記に結果を添付しました．
緑色が性能が良く，赤色になると性能が悪いと言う見方です．
SPAIは平均AUC 91.0 を達成し，どのベンチマークでも一貫して性能が高いのがわかります．
ベンチマーク上では，弱点が少ないと言うのはいい結果ですね．

[f:id:kurara_S:20251223164642p:plain]


<u>**<span style="font-size: 150%">画像の劣化に対する頑健性</span>**</u>

次に，SPAIの性質について実験した結果も見ていきましょう．

論文では，JPEG/WebP圧縮，ぼかし，ノイズ，リサイズといった実運用で考えられる画像の劣化に対する性能変化について実験がされています．
WebやSNS投稿・転送や撮影条件によるノイズなどの実世界で考えられる画像の変化ですね．

[f:id:kurara_S:20251223164851p:plain]

図は，SPAI（黄色）を含む複数手法のAUCを，各劣化操作の強さに対してプロットしたものです．
画像の左から順番に，JPEG・WebP圧縮・ぼかし・ノイズ・リサイズの操作による精度変化がプロットされています．

他手法に比べてリサイズで下落度合いが一番大きいなど，頑健性の面では一番良いとは言い難い場面は見られますが，ベースの性能が高いので問題はなさそうですね．


### 実装

本ブログでは，公開されている重みを使用してGoogle Colab上でSPAIを動作させることを目的とします．


まずは，リポジトリのクローンやパッケージのインストールを行います．

```
# 準備
%cd /content
!git clone https://github.com/mever-team/spai.git
%cd spai

!pip -q install --upgrade pip

# Colabでは numpy/tqdm の固定が衝突しやすいので除外して入れる
!grep -vE '^(numpy|tqdm)\b' requirements.txt > requirements.colab.txt
!pip -q install -r requirements.colab.txt
!pip -q install "numpy>=2.0,<2.3" "tqdm>=4.67"

# 追加依存
!pip -q install filetype gdown
```

著者らが公開しているImageNet上で学習された重みをweightsディレクトリに配置します．

```
# 重み取得
!mkdir -p weights
!gdown https://drive.google.com/uc?id=1vvXmZqs6TVJdj8iF1oJ4L_fcgdQrp_YI -O weights/spai.pth
```


推論させたい画像を用意します．
このとき，AI画像と実画像をフォルダで分けておくと，後でスコア分布を比較しやすくなります．

* /content/input_images/ai：生成画像（例：Gemini / Midjourney / SDなど）
* /content/input_images/real：実画像（スマホ写真，自前写真など）

```
# 画像読み込み
from google.colab import files
import os, shutil

BASE_DIR = "/content/input_images"

def upload_to(subdir: str, prompt: str):
    dst = os.path.join(BASE_DIR, subdir)
    os.makedirs(dst, exist_ok=True)

    print(f"\n=== {prompt} ===")
    print(f"保存先: {dst}")
    uploaded = files.upload()

    moved = 0
    for fn in uploaded.keys():
        shutil.move(fn, os.path.join(dst, fn))
        moved += 1
    print(f"アップロード完了: {moved} files -> {dst}")

upload_to("ai", "AI画像をアップロード")
upload_to("real", "実画像をアップロード")
```

いよいよ推論です．
以下の一行でSPAIを実行して終わりです．
/content/output_scores にcsvファイルが出力されているので，確認しましょう．

```
# SPAIでの推論を実行
!python -m spai infer --input /content/input_images/ai --output /content/output_scores
!python -m spai infer --input /content/input_images/real --output /content/output_scores
```


体感的には，写実的な写真ほど上手く分類ができており，イラスト画像やいわゆるなAI画像などはあまり上手く分類できていませんでした．
今回は，著者らが公開しているImageNet上で学習した重みを使用しているので当たり前ではありますが．
イラストなども交えたデータセットで学習を行えばまたかわるかもしれません．



いわゆるなAI画像の例:

[f:id:kurara_S:20251223161039p:plain:h300]

