---
Title: "【論文読み】ThermEval: A Structured Benchmark for Evaluation of Vision-Language Models on Thermal Imagery"
Category:
- 論文読み
- Artificial Intelligence
Draft: true
EditURL: https://blog.hatena.ne.jp/okojoai/okojoai.hatenablog.com/atom/entry/17179246901355707789
---

## 1. 3行まとめ

- 既存VLMはRGB画像では高性能だが、物理温度を符号化するサーマル画像では汎化せず、温度に基づく推論で一貫して失敗する
- ThermEval-Bは約55,000のサーマルVQAペアから成る構造化ベンチマークで、ThermEval-Dでは密なピクセル単位温度マップと身体部位アノテーションを提供
- 25種のVLMを評価した結果、カラーマップ変換で性能劣化し、言語事前分布や固定応答に依存 → プロンプティングやfine-tuningでも限定的改善のみ

## 2. 何が新しいか

既存のVLM評価はRGB中心で、色や質感に依存したベンチマークが主流 → サーマル画像が持つ物理温度情報を扱う能力は未評価。

本論文はThermEval-Bベンチマーク（約55,000 VQAペア）を構築し、温度推論の基礎能力を体系的に評価 → ThermEval-Dで初めてピクセル単位温度マップと身体部位セマンティクスを屋内外環境で収集。

25種のopen/closed VLMで評価 → 温度推論の失敗、カラーマップ変換への脆弱性、言語バイアスへの依存を定量化 → サーマル理解には専用評価が必須であることを実証。

## 3. 技術の核心

ThermEval-Bは以下の評価軸で構成：

1. **温度推論タスク**：ピクセル強度と物理温度の対応理解を要求
2. **カラーマップ不変性**：同一温度分布を異なるカラーマップ（Jet, Grayscale, Inferno等）で表現 → モデルが色依存か温度依存かを判定
3. **身体部位・シーン理解**：ThermEval-Dでdense annotation（体温 $T_{\text{part}}$ と部位ラベル $l \in \{\text{head, torso, limbs}\}$）を提供

評価指標は単純な精度ではなく、以下を分離：

$$
\text{Accuracy}_{\text{temp}} = \frac{1}{N}\sum_{i=1}^{N} \mathbb{1}[\hat{T}_i \in [T_i - \delta, T_i + \delta]]
$$

- $\delta$: 許容温度誤差（通常±2°C）
- $\hat{T}_i$: モデル予測温度、$T_i$: ground truth

カラーマップ変換下での性能差を測定：

$$
\Delta_{\text{colormap}} = \text{Acc}_{\text{default}} - \text{Acc}_{\text{transformed}}
$$

→ $\Delta > 0.1$なら色依存と判定。

## 4. 既存手法との比較

| 手法名 | アプローチ | サーマルタスク精度 | カラーマップ不変性 | 備考 |
|--------|-----------|-------------------|-------------------|------|
| [GPT-4V](https://openai.com/research/gpt-4v-system-card) | RGB事前学習VLM | 低（言語バイアス顕著） | 低（色依存） | プロンプティングで微改善のみ |
| [Claude 3.5 Sonnet](https://www.anthropic.com/claude) | RGB事前学習VLM | 中（固定応答に依存） | 低 | 温度推論で系統的エラー |
| [LLaVA-1.5](https://arxiv.org/abs/2310.03744) | オープンVLM | 低 | 低 | fine-tuning後も限定的向上 |
| [InternVL2](https://arxiv.org/abs/2404.16821) | マルチモーダル事前学習 | 中 | 中 | RGB能力は高いがサーマルで劣化 |
| [Qwen2-VL](https://arxiv.org/abs/2409.12191) | 高解像度VLM | 中 | 中 | 解像度向上でも温度理解は不足 |

※論文では25モデルを評価したが、代表的なものを抜粋。全モデルで温度推論精度 < 60%、カラーマップ変換で平均15%劣化。

## 5. 実装コード例

```python
import torch
import torch.nn as nn
from transformers import CLIPVisionModel, AutoTokenizer, AutoModel

class ThermalVLM(nn.Module):
    def __init__(self, vision_encoder, text_encoder, hidden_dim=768):
        super().__init__()
        self.vision_encoder = vision_encoder  # CLIP等のRGB encoder
        self.text_encoder = text_encoder
        
        # サーマル画像用の追加adapter層
        self.thermal_adapter = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        
        # 温度推論用のヘッド
        self.temp_head = nn.Linear(hidden_dim, 1)  # 温度値回帰
        
    def forward(self, thermal_image, question_ids):
        # thermal_image: [B, 1, H, W] (単一チャネル温度マップ)
        # RGB encoderに合わせて3チャネル化（カラーマップ適用）
        thermal_rgb = self.apply_colormap(thermal_image)  # [B, 3, H, W]
        
        # Vision encoding
        vision_feat = self.vision_encoder(thermal_rgb).last_hidden_state[:, 0]  # [B, D]
        
        # サーマル特化のadaptation
        thermal_feat = self.thermal_adapter(vision_feat)  # [B, D]
        
        # Text encoding
        text_feat = self.text_encoder(question_ids).last_hidden_state[:, 0]
        
        # Multimodal fusion
        fused = thermal_feat + text_feat  # 単純な加算（実際はattentionが望ましい）
        
        # 温度予測
        temp_pred = self.temp_head(fused)  # [B, 1]
        
        return temp_pred
    
    def apply_colormap(self, thermal_image):
        # 温度値 [T_min, T_max] を [0, 1] に正規化してカラーマップ適用
        # 実装ではJet, Inferno等を選択可能にする
        normalized = (thermal_image - thermal_image.min()) / (thermal_image.max() - thermal_image.min())
        return torch.cat([normalized] * 3, dim=1)  # 簡易的に3チャネル複製

# 学習時の損失関数
def thermal_vqa_loss(pred_temp, gt_temp, tolerance=2.0):
    # 温度誤差が許容範囲内なら損失ゼロ
    error = torch.abs(pred_temp - gt_temp)
    loss = torch.clamp(error - tolerance, min=0.0)
    return loss.mean()

# カラーマップ不変性の評価
def evaluate_colormap_invariance(model, dataloader, colormaps=['jet', 'gray', 'inferno']):
    results = {}
    for cmap in colormaps:
        correct = 0
        total = 0
        for batch in dataloader:
            thermal_img = batch['temperature_map']
            # カラーマップ変換を動的に適用
            model.colormap = cmap
            pred = model(thermal_img, batch['question_ids'])
            correct += (torch.abs(pred - batch['gt_temp']) < 2.0).sum().item()
            total += len(pred)
        results[cmap] = correct / total
    return results
```

## 6. 実装上の懸念

- **データ収集コスト**：ピクセル単位の温度キャリブレーションが必要 → サーマルカメラの較正情報とground truth温度計測が必須
- **カラーマップ依存性の除去**：既存VLMはRGB事前学習済み → 単一チャネル温度マップを直接処理する新architectureが理想だが、学習コストが増大
- **言語バイアス**：「体温は約36-37°C」等の事前知識に過度に依存 → 異常温度検出（発熱、低体温）で誤答が多発
- **メモリ使用量**：高解像度サーマル画像（640×480ピクセル、16-bit温度値）とVLMの組み合わせ → 推論時に12GB以上のVRAM消費
- **fine-tuningの限界**：論文の実験では教師ありfine-tuningでも精度向上は5-10%程度 → アーキテクチャレベルの改良が必要

## 7. よくある質問（FAQ）

**Q1: なぜ既存VLMはサーマル画像で性能が落ちるのか？**

A1: RGB事前学習では色・質感が主な特徴だが、サーマル画像は物理温度を符号化 → ピクセル強度と温度の線形対応を理解できない。カラーマップ変換で性能が15%劣化する事実が、色依存を裏付ける。

**Q2: ThermEval-Dの温度マップはどのように取得したのか？**

A2: 較正済みサーマルカメラで撮影し、複数の接触式温度計でground truthを測定 → ピクセル強度を温度値にマッピング。身体部位アノテーションは手動でセグメンテーション。屋内外で多様な環境条件をカバー。

**Q3: プロンプティングで改善できないのか？**

A3: 「温度を正確に読み取れ」等の指示を追加しても精度向上は3-5%程度。モデルが温度スケールを理解していない場合、言語指示だけでは補償不可能。

**Q4: サーマル画像専用のVLMを新規学習する必要があるか？**

A4: 論文の結果から、adapter層の追加やfine-tuningでは限界がある。単一チャネル温度入力を直接扱うvision encoderと、温度推論用の損失関数を組み込んだ専用モデルが望ましい。

**Q5: どのような応用分野で有用か？**

A5: 夜間監視、捜索救助、自動運転の歩行者検知、医療スクリーニング（発熱検出）、建物の断熱診断など、可視光が機能しない環境で活用。温度異常の自動検出には高精度なVLMが必須。

## 8. 検討メモ

- **自社データでの追試**：工場の設備監視サーマル画像にThermEval-Bを適用 → 異常温度検出精度を定量評価
- **カラーマップ非依存アーキテクチャの検討**：単一チャネル温度入力用のvision encoder（例: 1D convolution + temperature-aware positional encoding）を試作
- **温度校正データの収集方法**：接触式温度計との同時測定プロトコルを確立 → 社内サーマルカメラの較正精度を検証
- **エッジ実装の可能性**：軽量VLM（例: MobileVLM）にthermal adapterを追加 → Jetson等での推論速度とメモリ消費を測定
- **未解決の疑問**：カラーマップ変換をdata augmentationとして学習時に導入すれば不変性は向上するか？ → アブレーション実験が必要
- **ベンチマーク拡張**：産業用サーマル画像（溶接、電気設備）や医療用（血流可視化）をThermEvalに追加 → ドメイン特化評価の検討

---
> **原論文**: [ThermEval: A Structured Benchmark for Evaluation of Vision-Language Models on Thermal Imagery](https://arxiv.org/abs/2602.14989v1)
